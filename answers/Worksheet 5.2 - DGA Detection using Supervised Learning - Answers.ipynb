{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/GTK_Logo_Social Icon.jpg\" width=175 align=\"right\" />\n",
    "\n",
    "# Worksheet 5.2: DGA Detection - Answers\n",
    "This worksheet covers concepts covered in the second part of Module 5 - Supervised Learning.  It should take no more than 40-60 minutes to complete.  Please raise your hand if you get stuck.  \n",
    "\n",
    "## Import the Libraries\n",
    "For this exercise, we will be using:\n",
    "* Pandas (http://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Numpy (https://docs.scipy.org/doc/numpy/reference/)\n",
    "* Matplotlib (http://matplotlib.org/api/pyplot_api.html)\n",
    "* Scikit-learn (http://scikit-learn.org/stable/documentation.html)\n",
    "* YellowBrick (http://www.scikit-yb.org/en/latest/)\n",
    "* Seaborn (https://seaborn.pydata.org)\n",
    "* Lime (https://github.com/marcotcr/lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:17.797511Z",
     "start_time": "2023-08-01T15:18:14.835573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn import feature_extraction, tree, model_selection, metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import lime\n",
    "import io\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheet - DGA Detection using Machine Learning\n",
    "\n",
    "This worksheet is a step-by-step guide on how to detect domains that were generated using \"Domain Generation Algorithm\" (DGA). We will walk you through the process of transforming raw domain strings to Machine Learning features and creating a decision tree classifer which you will use to determine whether a given domain is legit or not. Once you have implemented the classifier, the worksheet will walk you through evaluating your model.  \n",
    "\n",
    "Overview 2 main steps:\n",
    "\n",
    "1. **Feature Engineering** - from raw domain strings to numeric Machine Learning features using DataFrame manipulations\n",
    "2. **Machine Learning Classification** - predict whether a domain is legit or not using a Decision Tree Classifier\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "**DGA - Background**\n",
    "\n",
    "\"Various families of malware use domain generation\n",
    "algorithms (DGAs) to generate a large number of pseudo-random\n",
    "domain names to connect to a command and control (C2) server.\n",
    "In order to block DGA C2 traffic, security organizations must\n",
    "first discover the algorithm by reverse engineering malware\n",
    "samples, then generate a list of domains for a given seed. The\n",
    "domains are then either preregistered, sink-holed or published\n",
    "in a DNS blacklist. This process is not only tedious, but can\n",
    "be readily circumvented by malware authors. An alternative\n",
    "approach to stop malware from using DGAs is to intercept DNS\n",
    "queries on a network and predict whether domains are DGA\n",
    "generated. Much of the previous work in DGA detection is based\n",
    "on finding groupings of like domains and using their statistical\n",
    "properties to determine if they are DGA generated. However,\n",
    "these techniques are run over large time windows and cannot be\n",
    "used for real-time detection and prevention. In addition, many of\n",
    "these techniques also use contextual information such as passive\n",
    "DNS and aggregations of all NXDomains throughout a network.\n",
    "Such requirements are not only costly to integrate, they may not\n",
    "be possible due to real-world constraints of many systems (such\n",
    "as endpoint detection). An alternative to these systems is a much\n",
    "harder problem: detect DGA generation on a per domain basis\n",
    "with no information except for the domain name. Previous work\n",
    "to solve this harder problem exhibits poor performance and many\n",
    "of these systems rely heavily on manual creation of features;\n",
    "a time consuming process that can easily be circumvented by\n",
    "malware authors...\"    \n",
    "[Citation: Woodbridge et. al 2016: \"Predicting Domain Generation Algorithms with Long Short-Term Memory Networks\"]\n",
    "\n",
    "A better alternative for real-world deployment would be to use \"featureless deep learning\" - We have a separate notebook where you can see how this can be implemented!\n",
    "\n",
    "**However, let's learn the basics first!!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breakpoint: Load Features and Labels\n",
    "\n",
    "If you got stuck in Part 1, please simply load the feature matrix we prepared for you, so you can move on to Part 2 and train a Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:21.084971Z",
     "start_time": "2023-08-01T15:18:21.054086Z"
    }
   },
   "outputs": [],
   "source": [
    "#load full dataset\n",
    "df_final = pd.read_csv('../data/dga_features_final_df.csv')\n",
    "\n",
    "#If you didn't get a working dataset, uncomment this line\n",
    "#df_final = pd.read_csv('../data/our_data_dga_features_final_df.csv')\n",
    "\n",
    "\n",
    "print(df_final['isDGA'].value_counts())\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Supervised Learning\n",
    "\n",
    "To learn simple classification procedures using [sklearn](http://scikit-learn.org/stable/) we have split the work flow into 5 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Feature matrix and ```target``` vector containing the URL labels\n",
    "\n",
    "- In statistics, the feature matrix is often referred to as ```X```\n",
    "- target is a vector containing the labels for each URL (often also called ```y``` in statistics)\n",
    "- In sklearn both the input and target can either be a pandas DataFrame/Series or numpy array/vector respectively (can't be lists!)\n",
    "\n",
    "Tasks:\n",
    "- 1.1 assign 'isDGA' column to a pandas Series named 'target'\n",
    "- 1.2 encode the strings as digits using sklearn ```LabelEncoder``` \n",
    "- 1.3 drop 'isDGA' column from ```df_final``` DataFrame and name the resulting pandas DataFrame ```feature_matrix```\n",
    "\n",
    "## 1.1 Create a variable named 'target' \n",
    "that contains whether the row was dga or legit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_final['isDGA']\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Encode strings as digits in the target variable\n",
    "\n",
    "LabelEncoder is an encoder from sklearn that will transform a target vector (not the features) into integers.\n",
    "\n",
    "[label encoder doc](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_model = LabelEncoder()\n",
    "encoded_target = label_encoder_model.fit_transform(target)\n",
    "\n",
    "# print our classes with the .classes_ method\n",
    "label_encoder_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at encoded targets\n",
    "encoded_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we like to encode targets using sklearn, is that once we are finished modeling, we can use the same model to turn it back into strings. This is really useful when plotting metrics or looking at the results (especially when you have more than one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform our encoded targets back into strings\n",
    "label_encoder_model.inverse_transform(encoded_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create the Feature Matrix\n",
    "\n",
    "In order to train a model you have to separate the features from the target in to separate objects. Drop **isDGA** column from ```df_final``` DataFrame and name the resulting pandas DataFrame ```feature_matrix```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:24.531780Z",
     "start_time": "2023-08-01T15:18:24.519783Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix = df_final.drop(['isDGA'], axis='columns')\n",
    "feature_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creata a list of our feature names for plotting later and if we need to pull the features again from the full dataframe.\n",
    "feature_names = feature_matrix.columns.to_list()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-Train split\n",
    "\n",
    "Tasks:\n",
    "- split your `feature_matrix` and `target` vector into **train** and **test** subsets using sklearn [model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "Output of the split should be 2 complete sets of data separated by features and labels: \n",
    " - feature_matrix_train: 75% of the feature matrix (data)\n",
    " - feature_matrix_test: the remaining 25% of the feature matrix\n",
    " - target_train: the labels for the train features\n",
    " - target_test: the labels for the test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:25.851436Z",
     "start_time": "2023-08-01T15:18:25.845963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data set into training and test data\n",
    "feature_matrix_train, feature_matrix_test, target_train, target_test = (model_selection.\n",
    "                                                                        train_test_split(\n",
    "                                                                           feature_matrix, \n",
    "                                                                           encoded_target,\n",
    "                                                                           test_size=0.25, \n",
    "                                                                           random_state=33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:26.416418Z",
     "start_time": "2023-08-01T15:18:26.409879Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:27.022254Z",
     "start_time": "2023-08-01T15:18:27.016273Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:27.581893Z",
     "start_time": "2023-08-01T15:18:27.576860Z"
    }
   },
   "outputs": [],
   "source": [
    "target_train[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:28.192324Z",
     "start_time": "2023-08-01T15:18:28.186738Z"
    }
   },
   "outputs": [],
   "source": [
    "target_test[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model and make a prediction\n",
    "\n",
    "Finally, we have prepared and segmented the data. Let's start classifying!!   \n",
    "\n",
    "Tasks:\n",
    "\n",
    "-  Use the sklearn [tree.DecisionTreeClassfier()](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), create a decision tree with default parameters, and train it using the ```.fit()``` function with ```feature_matrix_train``` and ```target_train``` data.\n",
    "-  Next, pull a few random rows from the data and see if your classifier got it correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree_model = tree.DecisionTreeClassifier()  \n",
    "d_tree_model = d_tree_model.fit(feature_matrix_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You trained the model. Now extract a row from the test set to see if the model can predict the correct answer by comparing it to the test target (ground truth). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:29.662395Z",
     "start_time": "2023-08-01T15:18:29.650006Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract a row from the test data\n",
    "\n",
    "row_number = 14\n",
    "test_feature = feature_matrix_test[row_number:row_number+1]\n",
    "\n",
    "# Make the prediction\n",
    "pred = d_tree_model.predict(test_feature)\n",
    "\n",
    "#Let's go back to having strings in the targets to compare \n",
    "#b/c it'e easier to read. We can do this using the inverse_transform from the label encoder model\n",
    "pred_string = label_encoder_model.inverse_transform(pred)\n",
    "\n",
    "# pull out the ground truth for this row\n",
    "test_target = target_test[row_number:row_number+1]\n",
    "# transfrom to a string\n",
    "test_target_string = label_encoder_model.inverse_transform(test_target)\n",
    "\n",
    "                                                    \n",
    "# print the results and the ground truth\n",
    "print('Predicted class:', pred_string)\n",
    "print('Ground truth class:', test_target_string)\n",
    "print('Accurate prediction?', pred_string == test_target_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess model performance\n",
    "\n",
    "- Make predictions for all your data. Call the ```.predict()``` method on the model ```d_tree_model``` with your test data ```feature_matrix_test``` and store the results in a variable called ```target_pred```. This will be data that the model has not 'seen' before so we will use these predictions to evaluate how well the model can predict the correct answer on new data by calling a few different metrics functions from our libraries like yellowbrick and sklearn.\n",
    "\n",
    "- Then calculate the accuracy using ```target_test``` (which are the true labels/ground truth) AND your models predictions on the test portion ```target_pred``` as inputs. The advantage here is to see how your model performs on new data it has not seen during the training phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on all of the test data\n",
    "target_pred = d_tree_model.predict(feature_matrix_test)\n",
    "\n",
    "# print a sample of the predictions\n",
    "print(target_pred[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the label_encoder_model from above to create a transformed version of these **target_pred** results and save as **transformed_test_predictions**. The transformation will take the data from from a vector of 0s and 1s back into a vector of strings ('dga', 'legit'). We do this because it will be much easier to interpret in our metrics and in any plots. \n",
    "\n",
    "- Creat a transformed version of the **target_test** data (ground truth) **transformed_target_test** so that when we compare the predictions against the truth it's in the same format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:36.474000Z",
     "start_time": "2023-08-01T15:18:36.465235Z"
    }
   },
   "outputs": [],
   "source": [
    "transformed_test_predictions = label_encoder_model.inverse_transform(target_pred)\n",
    "transformed_target_test = label_encoder_model.inverse_transform(target_test)\n",
    "\n",
    "# print a sample\n",
    "print(transformed_target_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use sklearn [metrics.accuracy_score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) to determine your model accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(transformed_target_test, transformed_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print out the confusion matrix using [metrics.confusion_matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix\\n', metrics.confusion_matrix(transformed_target_test, transformed_test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:37.020151Z",
     "start_time": "2023-08-01T15:18:37.008484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Classification Report...neat summary\n",
    "print(metrics.classification_report(transformed_target_test, transformed_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Yellowbrick's Classification Report and ConfusionMatrix function to visualize the classification report and confusion matrix. (https://www.scikit-yb.org/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:38.286653Z",
     "start_time": "2023-08-01T15:18:38.157607Z"
    }
   },
   "outputs": [],
   "source": [
    "viz = ConfusionMatrix(d_tree_model)\n",
    "viz.fit(feature_matrix_train, target_train)\n",
    "viz.score(feature_matrix_test, target_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:39.322025Z",
     "start_time": "2023-08-01T15:18:39.143579Z"
    }
   },
   "outputs": [],
   "source": [
    "viz = ClassificationReport(d_tree_model)\n",
    "viz.fit(feature_matrix_train, target_train)\n",
    "viz.score(feature_matrix_test, target_test)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Visualizing your Tree\n",
    "As an optional step, you can actually visualize your tree.  The following code will generate a graph of your decision tree.  You will need graphviz (http://www.graphviz.org) and pydotplus (or pydot) installed for this to work.\n",
    "The Griffon VM has this installed already, but if you try this on a Mac, or Linux machine you will need to install graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:48.770830Z",
     "start_time": "2023-08-01T15:18:44.387346Z"
    }
   },
   "outputs": [],
   "source": [
    "# These libraries are used to visualize the decision tree and require that you have GraphViz\n",
    "# and pydot or pydotplus installed on your computer.\n",
    "\n",
    "from IPython.core.display import Image\n",
    "import pydotplus as pydot\n",
    "\n",
    "\n",
    "dot_data = io.StringIO() \n",
    "tree.export_graphviz(d_tree_model, out_file=dot_data, \n",
    "                     feature_names=feature_names,\n",
    "                    filled=True, rounded=True,  \n",
    "                    special_characters=True) \n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models\n",
    "Now that you've built a Decision Tree, let's try out two other classifiers and see how they perform on this data.  For this next exercise, create classifiers using:\n",
    "\n",
    "* Support Vector Machine\n",
    "* Random Forest\n",
    "* K-Nearest Neighbors (http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)  \n",
    "\n",
    "Once you've done that, run the various performance metrics to determine which classifier works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:49.809825Z",
     "start_time": "2023-08-01T15:18:48.864954Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:52.587160Z",
     "start_time": "2023-08-01T15:18:52.555150Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create the Random Forest Classifier\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=10, \n",
    "                             max_depth=None, \n",
    "                             min_samples_split=2, \n",
    "                             random_state=0)\n",
    "\n",
    "random_forest_clf = random_forest_clf.fit(feature_matrix_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:53.867772Z",
     "start_time": "2023-08-01T15:18:53.860485Z"
    }
   },
   "outputs": [],
   "source": [
    "random_forest_predictions = random_forest_clf.predict(feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:54.765628Z",
     "start_time": "2023-08-01T15:18:54.579799Z"
    }
   },
   "outputs": [],
   "source": [
    "viz = ClassificationReport(random_forest_clf)\n",
    "viz.fit(feature_matrix_train, target_train)\n",
    "viz.score(feature_matrix_test, target_test)\n",
    "viz.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:55.707913Z",
     "start_time": "2023-08-01T15:18:55.702760Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(target_test, random_forest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:58.780600Z",
     "start_time": "2023-08-01T15:18:56.515258Z"
    }
   },
   "outputs": [],
   "source": [
    "#Next, create the SVM classifier\n",
    "svm_classifier = svm.SVC()\n",
    "svm_classifier = svm_classifier.fit(feature_matrix_train, target_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:18:58.927394Z",
     "start_time": "2023-08-01T15:18:58.886754Z"
    }
   },
   "outputs": [],
   "source": [
    "svm_preds = svm_classifier.predict(feature_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:19:03.005474Z",
     "start_time": "2023-08-01T15:19:02.774017Z"
    }
   },
   "outputs": [],
   "source": [
    "viz = ClassificationReport(svm_classifier)\n",
    "viz.fit(feature_matrix_train, target_train)\n",
    "viz.score(feature_matrix_test, target_test)\n",
    "viz.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:19:03.882478Z",
     "start_time": "2023-08-01T15:19:03.872959Z"
    }
   },
   "outputs": [],
   "source": [
    "#Finally the knn\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf = knn_clf.fit(feature_matrix_train, target_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:19:05.017786Z",
     "start_time": "2023-08-01T15:19:04.817406Z"
    }
   },
   "outputs": [],
   "source": [
    "viz = ClassificationReport(knn_clf)\n",
    "viz.fit(feature_matrix_train, target_train)\n",
    "viz.score(feature_matrix_test, target_test)\n",
    "viz.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain a Prediction\n",
    "In the example below, you can use LIME to explain how a classifier arrived at its prediction.  Try running LIME with the various classifiers you've created and various rows to see how it functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:19:06.696506Z",
     "start_time": "2023-08-01T15:19:06.685294Z"
    }
   },
   "outputs": [],
   "source": [
    "import lime.lime_tabular\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(feature_matrix_train, \n",
    "                                                   feature_names=feature_names, \n",
    "                                                   class_names=['legit', 'isDGA'], \n",
    "                                                   discretize_continuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:19:08.032806Z",
     "start_time": "2023-08-01T15:19:07.969509Z"
    }
   },
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(feature_matrix_test.iloc[12], \n",
    "                                 d_tree_model.predict_proba, \n",
    "                                 num_features=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:19:09.147922Z",
     "start_time": "2023-08-01T15:19:09.115756Z"
    }
   },
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True, show_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T15:19:14.408073Z",
     "start_time": "2023-08-01T15:19:14.402505Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_matrix_test.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Decision Tree for Worksheet 11\n",
    "filename = '../data/dga_decision_tree.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
